{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59185e24b47345d19948499a0a90411d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_641a70c733c84c09a43f295c803b7431",
              "IPY_MODEL_99ab3e28092440c6825e509b4b89bddf",
              "IPY_MODEL_80c677d5da2742ac91da13184beff0c4"
            ],
            "layout": "IPY_MODEL_cc47e66a42ef46c8813ed3cee90bcfc2"
          }
        },
        "641a70c733c84c09a43f295c803b7431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6a38b62f854b94a97b2598102b7f08",
            "placeholder": "​",
            "style": "IPY_MODEL_7452b729a87d408788fce65c6c3f8b68",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "99ab3e28092440c6825e509b4b89bddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7795b3671d144a0eb4781a4e4f37037d",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb475c94e44e4751af5a02f44d3bdb57",
            "value": 791656
          }
        },
        "80c677d5da2742ac91da13184beff0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2963ac266510471ca0456554c43ba913",
            "placeholder": "​",
            "style": "IPY_MODEL_e3cc9836339c4dc7be8040cd55c3d5aa",
            "value": " 792k/792k [00:00&lt;00:00, 14.6MB/s]"
          }
        },
        "cc47e66a42ef46c8813ed3cee90bcfc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6a38b62f854b94a97b2598102b7f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7452b729a87d408788fce65c6c3f8b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7795b3671d144a0eb4781a4e4f37037d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb475c94e44e4751af5a02f44d3bdb57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2963ac266510471ca0456554c43ba913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cc9836339c4dc7be8040cd55c3d5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22fbd5b54f224daea271a4cc72bf8588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56e48906d08f4613b95c9d0b2d163d2b",
              "IPY_MODEL_0aef95e56def48669443bb89cff43eee",
              "IPY_MODEL_7791718e7cd04852987836e048cddcfb"
            ],
            "layout": "IPY_MODEL_b48c12de4c9141efb870a283e54239d5"
          }
        },
        "56e48906d08f4613b95c9d0b2d163d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a3044e31cb4398b2f80a95ef77a6d4",
            "placeholder": "​",
            "style": "IPY_MODEL_933f240021354347a81179d92c439108",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0aef95e56def48669443bb89cff43eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d90ee4d4ff4a618cf2b8babf0d689a",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_314e6a0fb688484fba8923e3aced9a84",
            "value": 1208
          }
        },
        "7791718e7cd04852987836e048cddcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa63a1eb05c54a05a2763557bf1f4e98",
            "placeholder": "​",
            "style": "IPY_MODEL_f64e52cd40f242b5a30dc8ef30c9a9d4",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 37.7kB/s]"
          }
        },
        "b48c12de4c9141efb870a283e54239d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a3044e31cb4398b2f80a95ef77a6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933f240021354347a81179d92c439108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2d90ee4d4ff4a618cf2b8babf0d689a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314e6a0fb688484fba8923e3aced9a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa63a1eb05c54a05a2763557bf1f4e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64e52cd40f242b5a30dc8ef30c9a9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMwuJXbUtc3w",
        "outputId": "f98594f3-d96f-439e-8d6c-616056dda632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-extractive-summarizer\n",
            "  Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (3.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.22.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.10.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (8.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (23.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.4.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (67.7.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.27.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (6.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.8)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (4.65.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->bert-extractive-summarizer) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers->bert-extractive-summarizer) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->bert-extractive-summarizer) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->bert-extractive-summarizer) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.2)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, bert-extractive-summarizer\n",
            "Successfully installed bert-extractive-summarizer-0.10.1 huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-extractive-summarizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gingerit\n"
      ],
      "metadata": {
        "id": "stPh1tAbxx2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA1Mp5esuB3d",
        "outputId": "7d4ac19f-9294-4e4c-f92b-df7c5e97f8bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QopG8wBTuaI2",
        "outputId": "8a851ba0-ff01-48dd-a393-51693c25b6b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-k097lkb3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-k097lkb3\n",
            "  Resolved https://github.com/boudinfl/pke.git to commit ebd6e5754b4156a61a4ec6c4c283e821d11a36be\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.8.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.2.2)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (0.18.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.27.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (6.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.10.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (23.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.6)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (8.1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pke==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.2)\n",
            "Building wheels for collected packages: pke\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-2.0.0-py3-none-any.whl size=6160677 sha256=85c268b4ab05688f4737cddc037e35062a96e51df2087b9bb1337fec80a76800\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mlrcxu0z/wheels/8c/07/29/6b35bed2aa36e33d77ff3677eb716965ece4d2e56639ad0aab\n",
            "Successfully built pke\n",
            "Installing collected packages: unidecode, pke\n",
            "Successfully installed pke-2.0.0 unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbjPx6tbuvJh",
        "outputId": "f7d8c22d-0ce5-4f17-ea86-448dbe295e88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-28 16:51:46.623990: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 16:51:47.624717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "#!pip install git+https://github.com/boudinfl/pke.git\n",
        "#!python -m spacy download en\n",
        "#!pip install spacy==2.1.3 --upgrade --force-reinstall\n",
        "!pip install -U nltk\n",
        "!pip install -U pywsd\n",
        "!pip install -U wn==0.0.23\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install flashtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgEM5VBDuyNi",
        "outputId": "520fb2bb-68c8-4495-a9cc-0a5bf4e03fc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.5-py3-none-any.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pywsd) (3.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pywsd) (1.16.0)\n",
            "Collecting wn==0.0.23\n",
            "  Downloading wn-0.0.23.tar.gz (31.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.6/31.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pywsd) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pywsd) (1.22.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->pywsd) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pywsd) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pywsd) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->pywsd) (4.65.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pywsd) (2022.7.1)\n",
            "Building wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.23-py3-none-any.whl size=31792928 sha256=2c962d27e9a6f113a59df0ea5fe83bce435515b6d254e62c990d5cff2e86a212\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/1a/7d/23a76ce45998af60e47466a694c237fa26023c5674b47672b2\n",
            "Successfully built wn\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.5 wn-0.0.23\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wn==0.0.23 in /usr/local/lib/python3.10/dist-packages (0.0.23)\n",
            "2023-04-28 16:52:26.307862: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 16:52:27.120082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "2023-04-28 16:52:52.301347: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 16:52:53.563433: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9308 sha256=236badd0960c253f10e7bab759f2377d4041f63839ed5e51e8871d1940c66a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers==4.8.1\n",
        "!pip install --quiet sentence-transformers==2.2.2\n",
        "!pip install --quiet sentencepiece==0.1.95"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6TCV_r4vI9Z",
        "outputId": "294ba2a6-a8b0-4ceb-c6d9-3db57ad3b48e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.7/508.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restart runtime\n",
        "quit()"
      ],
      "metadata": {
        "id": "WwnIJ_nSvaOs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connection to GOoogle Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNZW8sei0dG6",
        "outputId": "24ab7a26-d222-4bef-bac5-0e4a588e9020"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Imports"
      ],
      "metadata": {
        "id": "h2EpXm2-D9lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import itertools\n",
        "import re\n",
        "import pke\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import random\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n"
      ],
      "metadata": {
        "id": "HsIBgBObEAL7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization Of Text"
      ],
      "metadata": {
        "id": "lg_V10HC2Ept"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from summarizer import Summarizer\n",
        "\n",
        "# Path of the text file\n",
        "file_path = \"/content/drive/MyDrive/Data/egpty.txt\"\n",
        "\n",
        "# read the file\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    full_text = file.read()\n",
        "\n",
        "# create the summarizer model\n",
        "summarizer_model = Summarizer()\n",
        "\n",
        "# set the summarization parameters\n",
        "min_length = 60\n",
        "max_length = 500\n",
        "ratio = 0.4\n",
        "\n",
        "# generate the summary\n",
        "result = summarizer_model(full_text, min_length=min_length, max_length=max_length, ratio=ratio)\n",
        "\n",
        "# convert the summary to a string\n",
        "summarized_text = ''.join(result)\n",
        "\n",
        "# print the summary\n",
        "print(summarized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seHYNLRw2IfZ",
        "outputId": "c53275f6-4734-40a1-a89f-032a286f2f4d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Nile River fed Egyptian civilization for hundreds of years. It begins near the equator in Africa and flows north to the Mediterranean Sea. This soil was fertile, which means it was good for growing crops. The red land was the barren desert beyond the fertile region. When the birds arrived, the annual flood waters would soon follow. Then they used a tool called a shaduf to spread the water across the fields. They were the first to grind wheat into flour and to mix the flour with yeast and water to make dough rise into bread. Egyptians often painted walls white to reflect the blazing heat. Poorer Egyptians simply went to the roof to cool off after sunset. Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa. Even during the cool season, chipping minerals out of the rock was miserable work. One ancient painting even shows a man ready to hit a catfish with a wooden hammer. A boomerang is a curved stick that returns to the person who threw it.) Eventually, Egyptians equipped their reed boats with sails and oars. Going south, they raised a sail and let the winds that blew in that direction push them. The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed. Ancient Egypt had no money, so people exchanged goods that they grew or made. This prosperity made life easier and provided greater opportunities for many Egyptians. For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records. Some skilled artisans erected stone or brick houses and temples. These traders took Egyptian products such as scrolls, linen, gold, and jewelry. Egyptians created a government that divided the empire into 42 provinces. Priests followed formal rituals and took care of the temples. Before entering a temple, a priest bathed and put on special linen garments and white sandals. So the ruler and the priests tried hard to keep the gods happy. By doing so, they hoped to maintain the social and political order. In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war. Unlike other ancient African cultures, in Egyptian society men and women had fairly equal rights. For example, they could both own and manage their own property. Children in Egypt played with toys such as dolls, animal figures, board games, and marbles. Almost all Egyptians married when they were in their early teens. Doctors believed that the heart controlled thought and the brain circulated blood, which is the opposite of what is known now. Early Egyptians created a hieroglyphic system with about 700 characters. Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls. Legend says a king named Narmer united Upper and Lower Egypt. Some historians think Narmer actually represents several kings who gradually joined the two lands. It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt. When a king died, one of his children usually took his place as ruler. The order in which members of a royal family inherit a throne is called the succession. Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom. Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt. The first rulers of Egypt were often buried in an underground tomb topped by mud brick. They replaced the mud brick with a small pyramid of brick or stone. It is called a step pyramid because its sides rise in a series of giant steps. He ordered the construction of the largest pyramid ever built. Miners cut the huge blocks of stone using copper saws and chisels. One reason is that the pyramids drew attention to the tombs inside them. Grave robbers broke into the tombs to steal the treasure buried with the pharaohs. Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife. During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings. This was to confuse grave robbers about which passage to take. Sometimes relatives, such as the queen, were buried in the extra rooms. Tombs were supposed to be the palaces of pharaohs in the afterlife. Mourners filled the tomb with objects ranging from food to furniture that the mummified pharaoh would need. A sculpture of a dead pharaoh had “perfect” features, no matter how he really looked. Such activities included growing and preparing food, caring for animals, and building boats. Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched. The dazzling riches found in this tomb show how much wealth the pharaohs spent preparing for the afterlife. By about 2130 B.C., Egyptian kings began to lose their power to local rulers of the provinces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(summarized_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2JB8ype3Fov",
        "outputId": "e444650c-1834-472e-c5cb-eb8397bc6656"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RykBa-l5IkD",
        "outputId": "4d93d322-bd3d-427d-8965-6ed226a2181e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Nile River fed Egyptian civilization for hundreds of years. It begins near the equator in Africa and flows north to the Mediterranean Sea. This soil was fertile, which means it was good for growing crops. The red land was the barren desert beyond the fertile region. When the birds arrived, the annual flood waters would soon follow. Then they used a tool called a shaduf to spread the water across the fields. They were the first to grind wheat into flour and to mix the flour with yeast and water to make dough rise into bread. Egyptians often painted walls white to reflect the blazing heat. Poorer Egyptians simply went to the roof to cool off after sunset. Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa. Even during the cool season, chipping minerals out of the rock was miserable work. One ancient painting even shows a man ready to hit a catfish with a wooden hammer. A boomerang is a curved stick that returns to the person who threw it.) Eventually, Egyptians equipped their reed boats with sails and oars. Going south, they raised a sail and let the winds that blew in that direction push them. The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed. Ancient Egypt had no money, so people exchanged goods that they grew or made. This prosperity made life easier and provided greater opportunities for many Egyptians. For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records. Some skilled artisans erected stone or brick houses and temples. These traders took Egyptian products such as scrolls, linen, gold, and jewelry. Egyptians created a government that divided the empire into 42 provinces. Priests followed formal rituals and took care of the temples. Before entering a temple, a priest bathed and put on special linen garments and white sandals. So the ruler and the priests tried hard to keep the gods happy. By doing so, they hoped to maintain the social and political order. In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war. Unlike other ancient African cultures, in Egyptian society men and women had fairly equal rights. For example, they could both own and manage their own property. Children in Egypt played with toys such as dolls, animal figures, board games, and marbles. Almost all Egyptians married when they were in their early teens. Doctors believed that the heart controlled thought and the brain circulated blood, which is the opposite of what is known now. Early Egyptians created a hieroglyphic system with about 700 characters. Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls. Legend says a king named Narmer united Upper and Lower Egypt. Some historians think Narmer actually represents several kings who gradually joined the two lands. It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt. When a king died, one of his children usually took his place as ruler. The order in which members of a royal family inherit a throne is called the succession. Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom. Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt. The first rulers of Egypt were often buried in an underground tomb topped by mud brick. They replaced the mud brick with a small pyramid of brick or stone. It is called a step pyramid because its sides rise in a series of giant steps. He ordered the construction of the largest pyramid ever built. Miners cut the huge blocks of stone using copper saws and chisels. One reason is that the pyramids drew attention to the tombs inside them. Grave robbers broke into the tombs to steal the treasure buried with the pharaohs. Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife. During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings. This was to confuse grave robbers about which passage to take. Sometimes relatives, such as the queen, were buried in the extra rooms. Tombs were supposed to be the palaces of pharaohs in the afterlife. Mourners filled the tomb with objects ranging from food to furniture that the mummified pharaoh would need. A sculpture of a dead pharaoh had “perfect” features, no matter how he really looked. Such activities included growing and preparing food, caring for animals, and building boats. Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched. The dazzling riches found in this tomb show how much wealth the pharaohs spent preparing for the afterlife. By about 2130 B.C., Egyptian kings began to lose their power to local rulers of the provinces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyword Generation\n",
        "Here we are using entire text to generate the keywords becuase the summarized text might not have entire set"
      ],
      "metadata": {
        "id": "TfXXzzU25T2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keyphrases(text):\n",
        "    # Initialize the MultipartiteRank extractor\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    \n",
        "    # Set the part-of-speech tags to select candidates from\n",
        "    pos = {'PROPN'}\n",
        "    \n",
        "    # Set the stoplist to filter out unwanted words, including special symbols\n",
        "    stoplist = list(string.punctuation)\n",
        "    #if we work on different language we use another supported language\n",
        "    stoplist =stoplist + stopwords.words('english')\n",
        "    # like -lrb-, -rrb-, -lcb-, -rcb-, -lsb-, and -rsb-\n",
        "    stoplist =stoplist + ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "   \n",
        "    \n",
        "    # Load the document into the extractor\n",
        "    extractor.load_document(input=text, language='en',\n",
        "                             stoplist=stoplist,\n",
        "                             normalization=None)\n",
        "    \n",
        "    # Select candidate keyphrases based on their part-of-speech tags\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "    \n",
        "    # Calculate the weights of the candidate keyphrases\n",
        "    extractor.candidate_weighting(alpha=1.1,\n",
        "                                  threshold=0.75,\n",
        "                                  method='average')\n",
        "    \n",
        "    # Get the top 25 keyphrases\n",
        "    keyphrases = extractor.get_n_best(n=20)\n",
        "    \n",
        "    # Return a list of the top keyphrases\n",
        "    return [key[0] for key in keyphrases]\n",
        "\n",
        "\n",
        "# Get a list of candidate keyphrases\n",
        "keywords = extract_keyphrases(full_text) \n",
        "\n",
        "# Print the candidate keyphrases\n",
        "print(f\"Keywords: {keywords}\")\n",
        "\n",
        "# Filter out keyphrases that are not in the summarized text\n",
        "filtered_key_words = [keyword for keyword in keywords if keyword.lower() in summarized_text.lower()]\n",
        "\n",
        "# Print the filtered keyphrases\n",
        "print(f\"Keywords finalized presnt in summarized text {filtered_key_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE4eX6MHCd7_",
        "outputId": "e1590c2c-53e8-4b80-e77b-c9bc5fbea5fd"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keywords: ['egyptians', 'nile river', 'egypt', 'nile', 'euphrates', 'pharaoh', 'tigris', 'old kingdom', 'red land', 'double crown', 'lower egypt', 'longest river', 'narmer united upper', 'crown', 'africa', 'mediterranean sea', 'hyksos', 'new kingdom', 'black land', 'ethiopia']\n",
            "Keywords finalized presnt in summarized text ['egyptians', 'nile river', 'egypt', 'nile', 'pharaoh', 'old kingdom', 'red land', 'lower egypt', 'narmer united upper', 'crown', 'africa', 'mediterranean sea', 'new kingdom']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Mapping\n",
        "Map each keyword to a list of sentences that contain that keyword in summarized text."
      ],
      "metadata": {
        "id": "5SSvMrcCFWix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import flashtext\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def sentence_tokenization(text):\n",
        "    \"\"\"Tokenize the input text into a list of sentences\"\"\"\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    return [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "\n",
        "def map_keywords_to_sentences(keywords, sentences):\n",
        "    \"\"\"\n",
        "    Map each keyword to the sentences in which it appears in the input list of sentences\n",
        "    Return a dictionary with the format {keyword: [sentence1, sentence2, ...]}\n",
        "    \"\"\"\n",
        "    keyword_processor = flashtext.KeywordProcessor(case_sensitive=False)\n",
        "    keyword_sentence_map = {keyword: [] for keyword in keywords}\n",
        "    for keyword in keywords:\n",
        "        keyword_processor.add_keyword(keyword)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for keyword in keyword_processor.extract_keywords(sentence):\n",
        "            keyword_sentence_map[keyword].append(sentence)\n",
        "\n",
        "    return {keyword: sorted(sentences, key=len, reverse=True) for keyword, sentences in keyword_sentence_map.items()}\n",
        "\n",
        "def get_keyword_sentence_mapping(summarized_text, keywords):\n",
        "    \"\"\"\n",
        "    Tokenize the input summarized text into a list of sentences\n",
        "    Map each keyword to the sentences in which it appears in the list of sentences\n",
        "    Return a dictionary with the format {keyword: [sentence1, sentence2, ...]}\n",
        "    \"\"\"\n",
        "    sentences = sentence_tokenization(summarized_text)\n",
        "    return map_keywords_to_sentences(keywords, sentences)\n",
        "\n",
        "\n",
        "\n",
        "keyword_sentence_mapping = get_keyword_sentence_mapping(summarized_text, filtered_key_words)\n",
        "print(keyword_sentence_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuJYu_NjFmUO",
        "outputId": "46437ff8-01d4-4ddb-a6cd-9e07463e66e3"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'egyptians': ['Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records.', 'Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife.', 'This prosperity made life easier and provided greater opportunities for many Egyptians.', 'Egyptians created a government that divided the empire into 42 provinces.', 'Early Egyptians created a hieroglyphic system with about 700 characters.', 'Eventually, Egyptians equipped their reed boats with sails and oars.', 'Poorer Egyptians simply went to the roof to cool off after sunset.', 'Almost all Egyptians married when they were in their early teens.', 'Egyptians often painted walls white to reflect the blazing heat.'], 'nile river': ['The Nile River fed Egyptian civilization for hundreds of years.'], 'egypt': ['Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war.', 'Children in Egypt played with toys such as dolls, animal figures, board games, and marbles.', 'The first rulers of Egypt were often buried in an underground tomb topped by mud brick.', 'Ancient Egypt had no money, so people exchanged goods that they grew or made.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.'], 'nile': ['The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa.'], 'pharaoh': ['Mourners filled the tomb with objects ranging from food to furniture that the mummified pharaoh would need.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched.', 'A sculpture of a dead pharaoh had “perfect” features, no matter how he really looked.'], 'old kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.'], 'red land': ['The red land was the barren desert beyond the fertile region.'], 'lower egypt': ['It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'Legend says a king named Narmer united Upper and Lower Egypt.'], 'narmer united upper': ['Legend says a king named Narmer united Upper and Lower Egypt.'], 'crown': ['It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.'], 'africa': ['Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa.', 'It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'mediterranean sea': ['It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'new kingdom': ['During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings.', 'Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'Only a secret tomb built for a New Kingdom pharaoh was ever found with much of its treasure untouched.']}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genration of Fill in the Blanks Question with answer below\n",
        "Here we are matching the keywork in the sentence and makin it as blank and also correcting the sentence Grammatically"
      ],
      "metadata": {
        "id": "AU4a__kL2Cpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To correct the sentence grammaticallly\n",
        "from gingerit.gingerit import GingerIt\n",
        "\n",
        "def correct_sentence_grammar(sentence):\n",
        "    parser = GingerIt()\n",
        "    result = parser.parse(sentence)\n",
        "    corrected = result['result']\n",
        "    return corrected\n"
      ],
      "metadata": {
        "id": "RXkhv0GOvgyE"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def generate_fill_blanks(keyword_sentence_mapping):\n",
        "  \"\"\"\n",
        "  # This function called generate_fill_blanks which mainly used to genrate the fill in the blanks\n",
        "  that takes a sentence and keyword dictionary as input\n",
        "  outputs a fill in the blanks questions\n",
        "  \"\"\"\n",
        "  \n",
        "  # Create an empty list to store the fill-in-the-blank questions\n",
        "  fillblanks=[]\n",
        "  \n",
        "  # Loop through each keyword in the dictionary\n",
        "  for keyword in keyword_sentence_mapping:\n",
        "    count=0\n",
        "    \n",
        "    # Loop through each sentence associated with the current keyword\n",
        "    for sentence in keyword_sentence_mapping[keyword]:\n",
        "      count+=1\n",
        "      if count>5:\n",
        "        break\n",
        "      \n",
        "      # Call a function called correct_sentence_grammar to correct any grammatical errors in the sentence\n",
        "      sentence=correct_sentence_grammar(sentence)\n",
        "      \n",
        "      # Define a regular expression pattern to match special characters in the sentence\n",
        "      pattern = r'[@:;\\.\\-_\\!\\?\\'\\\"“”‘’&$%#\\^\\*\\(\\)\\[\\]\\{\\}]'\n",
        "      \n",
        "      # Use the re.sub() function to replace all occurrences of the pattern with an empty string\n",
        "      sentence = re.sub(pattern, '', sentence)\n",
        "      \n",
        "      # Check if the current keyword exists in the dictionary and if there are any sentences associated with that keyword\n",
        "      # Also check if the length of the sentence is less than or equal to 30 words\n",
        "      if keyword not in keyword_sentence_mapping or not keyword_sentence_mapping[keyword] or len(sentence.split(\" \"))>30:\n",
        "        \n",
        "        # If any of these conditions are not met, skip the current sentence and move on to the next one\n",
        "        continue\n",
        "      \n",
        "      # Compile a regular expression pattern using the current keyword and set the IGNORECASE flag to ignore case sensitivity\n",
        "      pattern = re.compile(keyword, re.IGNORECASE)\n",
        "      \n",
        "      # Use the sub() method of the pattern object to replace all occurrences of the keyword in the sentence with the string \" _______ \"\n",
        "      output = pattern.sub(\" _______ \", sentence)\n",
        "      \n",
        "      # Append a dictionary with two keys - \"question\" and \"answer\" - to the fillblanks list\n",
        "      # The \"question\" key contains the modified sentence with the blank space, and the \"answer\" key contains the keyword associated with that sentence\n",
        "      fillblanks.append({\"question\": output,\"answer\":keyword})\n",
        "  \n",
        "  # Return the fillblanks list containing all the generated fill-in-the-blank questions and their respective answers\n",
        "  return fillblanks\n"
      ],
      "metadata": {
        "id": "vOB__rWhNTek"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions=generate_fill_blanks(keyword_sentence_mapping)\n",
        "\n",
        "print(\"******************\")\n",
        "print(\"Fill in the Blanks\")\n",
        "print(\"******************\\n\\n\")\n",
        "#Ranmizing the generated fill in the blanks\n",
        "random.shuffle(questions)\n",
        "for i, question in enumerate(questions):\n",
        "    print(f\"{i+1}) {question['question']}\")\n",
        "    print(\"Answer is:\",question['answer'])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiyxExOPra98",
        "outputId": "d9bb0e94-ee8f-49be-ca5e-7f91ccde19cc"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************\n",
            "Fill in the Blanks\n",
            "******************\n",
            "\n",
            "\n",
            "1) Only a secret tomb built for a  _______  Pharaoh was ever found  much of its treasure untouched\n",
            "Answer is: new kingdom\n",
            "\n",
            "\n",
            "2) The  _______  provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed\n",
            "Answer is: nile\n",
            "\n",
            "\n",
            "3) A sculpture of a dead  _______  had perfect features, no matter how he really looked\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "4) Nubia was the Egyptian name for the area of the upper  _______  that had the richest gold mines in Africa\n",
            "Answer is: nile\n",
            "\n",
            "\n",
            "5) Children in  _______  played with toys such as dolls, animal figures, board games, and marbles\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "6) It begins near the equator in Africa and flows north to the  _______ \n",
            "Answer is: mediterranean sea\n",
            "\n",
            "\n",
            "7) During the  _______ , Pharaohs began building more secret tombs in an area called the Valley of the Kings\n",
            "Answer is: new kingdom\n",
            "\n",
            "\n",
            "8) The  _______  was the barren desert beyond the fertile region\n",
            "Answer is: red land\n",
            "\n",
            "\n",
            "9) The Nile provided so well for  _______  that sometimes they had surpluses, or more goods than they needed\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "10) Ancient  _______  had no money, so people exchanged goods that they grew or made\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "11) Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the  _______ \n",
            "Answer is: new kingdom\n",
            "\n",
            "\n",
            "12) It combined the red Crown of  _______  with the White Crown of Upper Egypt\n",
            "Answer is: lower egypt\n",
            "\n",
            "\n",
            "13) Historians divide ancient Egyptian dynasties into the  _______ , the Middle Kingdom, and the New Kingdom\n",
            "Answer is: old kingdom\n",
            "\n",
            "\n",
            "14) The first rulers of  _______  were often buried in an underground tomb topped by mud brick\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "15) Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in  _______ \n",
            "Answer is: africa\n",
            "\n",
            "\n",
            "16) Mourners filled the tomb with objects ranging from food to furniture that the mummified  _______  would need\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "17) Only a secret tomb built for a New Kingdom  _______  was ever found  much of its treasure untouched\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "18) In  _______ , people became slaves if they owed a debt, committed a crime, or were captured in war\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "19) This prosperity made life easier and provided greater opportunities for many  _______ \n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "20) It combined the red  _______  of Lower Egypt with the White  _______  of Upper Egypt\n",
            "Answer is: crown\n",
            "\n",
            "\n",
            "21) It combined the red  _______  of Lower Egypt with the White  _______  of Upper Egypt\n",
            "Answer is: crown\n",
            "\n",
            "\n",
            "22) It begins near the equator in  _______  and flows north to the Mediterranean Sea\n",
            "Answer is: africa\n",
            "\n",
            "\n",
            "23) The  _______  fed Egyptian civilization for hundreds of years\n",
            "Answer is: nile river\n",
            "\n",
            "\n",
            "24) Because the Pharaoh was thought to be a god, government and religion were not separate in ancient  _______ \n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "25) Legend says a king named Narmer united Upper and  _______ \n",
            "Answer is: lower egypt\n",
            "\n",
            "\n",
            "26)  _______  cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "27) Because the  _______  was thought to be a god, government and religion were not separate in ancient Egypt\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "28)  _______  believed that if a tomb was robbed, the person buried there could not have a happy afterlife\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "29) Legend says a king named  _______  and Lower Egypt\n",
            "Answer is: narmer united upper\n",
            "\n",
            "\n",
            "30) For example, some ancient  _______  learned to be scribes, people whose job was to write and keep records\n",
            "Answer is: egyptians\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Genrating the Multiple Choice Question along with the distractors\n",
        "Here we have used 2 different concepts to genrate the distrators \n",
        "1.   Wordnet\n",
        "2.   Conceptnet\n",
        "ANd after that we have used a pretrained mode on squad dataset to generate a question based on the sentence\n",
        "Finally we have Randomized the question along with options"
      ],
      "metadata": {
        "id": "XXDdz-GX2x4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing T5 Transformer\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n"
      ],
      "metadata": {
        "id": "XJ5VH9LdhskY"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "59185e24b47345d19948499a0a90411d",
            "641a70c733c84c09a43f295c803b7431",
            "99ab3e28092440c6825e509b4b89bddf",
            "80c677d5da2742ac91da13184beff0c4",
            "cc47e66a42ef46c8813ed3cee90bcfc2",
            "db6a38b62f854b94a97b2598102b7f08",
            "7452b729a87d408788fce65c6c3f8b68",
            "7795b3671d144a0eb4781a4e4f37037d",
            "bb475c94e44e4751af5a02f44d3bdb57",
            "2963ac266510471ca0456554c43ba913",
            "e3cc9836339c4dc7be8040cd55c3d5aa",
            "22fbd5b54f224daea271a4cc72bf8588",
            "56e48906d08f4613b95c9d0b2d163d2b",
            "0aef95e56def48669443bb89cff43eee",
            "7791718e7cd04852987836e048cddcfb",
            "b48c12de4c9141efb870a283e54239d5",
            "98a3044e31cb4398b2f80a95ef77a6d4",
            "933f240021354347a81179d92c439108",
            "d2d90ee4d4ff4a618cf2b8babf0d689a",
            "314e6a0fb688484fba8923e3aced9a84",
            "aa63a1eb05c54a05a2763557bf1f4e98",
            "f64e52cd40f242b5a30dc8ef30c9a9d4"
          ]
        },
        "id": "X9rLorg1hx9X",
        "outputId": "d4793a42-e942-4ec2-891f-95d85c0abd52"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59185e24b47345d19948499a0a90411d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22fbd5b54f224daea271a4cc72bf8588"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required modules\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "# Load the pre-trained T5 model for text summarization\n",
        "summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "\n",
        "# Load the pre-trained T5 tokenizer\n",
        "summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "# Set the device to GPU if available, otherwise to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the summary model to the selected device\n",
        "summary_model = summary_model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh7CZMQ5h34M",
        "outputId": "521d9966-3a58-4452-8ebb-1c14362eaec9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the Pre trained model from hugging face\n",
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_model = question_model.to(device)"
      ],
      "metadata": {
        "id": "Is04i_Zph53Y"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_question(context, answer, model, tokenizer):\n",
        "  \"\"\"\n",
        "  This function that generates a question based on a given context and answer\n",
        "  \"\"\"\n",
        "  # Combine the context and answer strings into a single string with a specific format\n",
        "  text = \"context: {} answer: {}\".format(context, answer)\n",
        "  \n",
        "  # Tokenize the text using the provided tokenizer, and encode it as PyTorch tensors\n",
        "  encoding = tokenizer.encode_plus(text, max_length=384, pad_to_max_length=False, truncation=True, return_tensors=\"pt\").to(device)\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  # Generate a question using the provided model, based on the input IDs and attention mask tensors\n",
        "  outs = model.generate(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        early_stopping=True,\n",
        "                        num_beams=5,\n",
        "                        num_return_sequences=1,\n",
        "                        no_repeat_ngram_size=2,\n",
        "                        max_length=72)\n",
        "\n",
        "  # Decode the generated question from the output tensors using the provided tokenizer\n",
        "  dec = [tokenizer.decode(ids, skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "  # Extract the question string from the decoded output, and remove any leading/trailing whitespace\n",
        "  question = dec[0].replace(\"question:\", \"\")\n",
        "  question = question.strip()\n",
        "\n",
        "  # Return the generated question string\n",
        "  return question\n"
      ],
      "metadata": {
        "id": "wHI_HzhMiA-H"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation of Distrators"
      ],
      "metadata": {
        "id": "MHGgojdS4Lnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This is used to generate distractors (incorrect answer choices) for a given word in a multiple choice question.\n",
        "It uses the WordNet corpus and the ConceptNet API to gather related words and hyponyms of the given word, and then selects a subset of those words as distractors.\n",
        "\"\"\"\n",
        "class WordDistractorGenerator:\n",
        "    def __init__(self):\n",
        "        self.distractor_lists = {}\n",
        "\n",
        "    def generate_distractor_list(self, word):\n",
        "        # Check if distractors for this word have already been generated and return them\n",
        "        if word in self.distractor_lists:\n",
        "            return self.distractor_lists[word]\n",
        "\n",
        "        # Retrieve the hyponyms (a type of word derived from a hypernym) for the given word from WordNet\n",
        "        synsets = wn.synsets(word, 'n')\n",
        "        if not synsets:\n",
        "            self.distractor_lists[word] = []\n",
        "            return []\n",
        "\n",
        "        hyponyms = synsets[0].hyponyms()\n",
        "\n",
        "        # Collect hyponyms' lemmas (specific words) and add them to the distractor list\n",
        "        distractor_list = [lemma.name().replace(\"_\", \" \").capitalize() for syn in hyponyms for lemma in syn.lemmas() if lemma.name() != word]\n",
        "\n",
        "        # Collect more words from ConceptNet API which are 'part of' the given word and add them to the distractor list\n",
        "        url = f\"http://api.conceptnet.io/query?node=/c/en/{word}/n&rel=/r/PartOf&start=/c/en/{word}&limit=5\"\n",
        "        response = requests.get(url).json()\n",
        "\n",
        "        for edge in response[\"edges\"]:\n",
        "            link = edge[\"end\"][\"term\"]\n",
        "            url2 = f\"http://api.conceptnet.io/query?node={link}&rel=/r/PartOf&end={link}&limit=10\"\n",
        "            response2 = requests.get(url2).json()\n",
        "            for edge in response2[\"edges\"]:\n",
        "                word2 = edge[\"start\"][\"label\"]\n",
        "                # Add word to distractor list if it is not equal to the original word and is not already in the list\n",
        "                if word2.lower() != word.lower() and word2.capitalize() not in distractor_list:\n",
        "                    distractor_list.append(word2.capitalize())\n",
        "\n",
        "        self.distractor_lists[word] = distractor_list\n",
        "        return distractor_list\n"
      ],
      "metadata": {
        "id": "JVo0dXT8eZnD"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_question(keyword_sentence_mapping, keyword):\n",
        "\n",
        "      \"\"\"\n",
        "      This function takes a sentence and keyword as an input and give a question along with the 4 options and answer to the specfic sentence\n",
        "      \"\"\"\n",
        "        # create a WordDistractorGenerator object\n",
        "      generator = WordDistractorGenerator()\n",
        "      \n",
        "      # get the sentence associated with the keyword\n",
        "      sentence = keyword_sentence_mapping\n",
        "\n",
        "      # generate a question from the sentence and the keyword\n",
        "      output = get_question(sentence,keyword,question_model,question_tokenizer)\n",
        "\n",
        "      # generate a list of distractor options for the question\n",
        "      distractor_list = generator.generate_distractor_list(keyword)\n",
        "\n",
        "      # if there are no distractor options, return None\n",
        "      if not distractor_list:\n",
        "          return None\n",
        "\n",
        "      # create a list of answer options that includes three distractors and the correct keyword\n",
        "      options = random.sample(distractor_list, min(len(distractor_list), 3)) + [keyword.capitalize()]\n",
        "\n",
        "      # shuffle the options\n",
        "      random.shuffle(options)\n",
        "\n",
        "      # return a dictionary with the question, options, and correct answer\n",
        "      return {\"question\": output, \"options\": options,\"answer\":keyword}\n"
      ],
      "metadata": {
        "id": "ph7MdiGdee66"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is to call the functions to genrate the mcqs\n",
        "def main(keyword_sentence_mapping):\n",
        "    questions = []\n",
        "\n",
        "    for keyword in keyword_sentence_mapping:\n",
        "      for sentence in keyword_sentence_mapping[keyword]:\n",
        "          #print(sentence)\n",
        "          question = generate_question(sentence, keyword)\n",
        "          if question:\n",
        "              questions.append(question)\n",
        "\n",
        "    print(\"************************\")\n",
        "    print(\"MUltiple Choice Quetions\")\n",
        "    print(\"************************\\n\\n\")\n",
        "    random.shuffle(questions)\n",
        "    for i, question in enumerate(questions):\n",
        "        print(f\"{i+1}) {question['question']}\")\n",
        "        for j, option in enumerate(question['options']):\n",
        "            print(f\"   {chr(ord('a')+j)}) {option}\")\n",
        "        print(\"Answer is:\",question['answer'])\n",
        "        print(\"\\n\")\n",
        "    return questions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    questions=main(keyword_sentence_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLTH6zxSejQ5",
        "outputId": "9bfabf0e-42f7-4388-b7a1-1003236024e5"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************\n",
            "MUltiple Choice Quetions\n",
            "************************\n",
            "\n",
            "\n",
            "1) Who married when they were in their teens?\n",
            "   a) Copt\n",
            "   b) Egyptians\n",
            "   c) Nubian\n",
            "   d) Cairene\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "2) What was the red color of the crown of Lower Egypt?\n",
            "   a) Dentine\n",
            "   b) Shoulder\n",
            "   c) A limb\n",
            "   d) Crown\n",
            "Answer is: crown\n",
            "\n",
            "\n",
            "3) In what country did children play with toys?\n",
            "   a) Israel\n",
            "   b) Egypt\n",
            "   c) Sierra leone\n",
            "   d) Lake tanganyika\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "4) What was the mummified pharaoh?\n",
            "   a) Pharaoh\n",
            "   b) Khufu\n",
            "   c) Cheops\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "5) What continent had the richest gold mines in the upper Nile?\n",
            "   a) Eurasia\n",
            "   b) Old world\n",
            "   c) Australia\n",
            "   d) Africa\n",
            "Answer is: africa\n",
            "\n",
            "\n",
            "6) What combined the red crown of Lower Egypt with the white Crown of Upper Egypt?\n",
            "   a) Israel\n",
            "   b) Shari\n",
            "   c) Egypt\n",
            "   d) Mauritania\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "7) What people painted their walls white to reflect the heat?\n",
            "   a) Theban\n",
            "   b) Copt\n",
            "   c) Nubian\n",
            "   d) Egyptians\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "8) The Nile provided so well for whom?\n",
            "   a) Cairene\n",
            "   b) Theban\n",
            "   c) Egyptians\n",
            "   d) Nubian\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "9) Who believed that if a tomb was robbed, the person buried there couldn't have happy afterlife?\n",
            "   a) Egyptians\n",
            "   b) Theban\n",
            "   c) Cairene\n",
            "   d) Nubian\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "10) What group of people had more opportunities because of the prosperity?\n",
            "   a) Nubian\n",
            "   b) Egyptians\n",
            "   c) Theban\n",
            "   d) Cairene\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "11) Who equipped their boats with sails and oars?\n",
            "   a) Theban\n",
            "   b) Egyptians\n",
            "   c) Nubian\n",
            "   d) Cairene\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "12) A sculpture of a dead pharaoh had perfect features, no matter how he looked?\n",
            "   a) Khufu\n",
            "   b) Pharaoh\n",
            "   c) Cheops\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "13) Who was the tomb built for?\n",
            "   a) Cheops\n",
            "   b) Pharaoh\n",
            "   c) Khufu\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "14) Who created a hieroglyphic system with 700 characters?\n",
            "   a) Egyptians\n",
            "   b) Nubian\n",
            "   c) Cairene\n",
            "   d) Copt\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "15) Who went to the roof to cool off after sunset?\n",
            "   a) Copt\n",
            "   b) Nubian\n",
            "   c) Egyptians\n",
            "   d) Cairene\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "16) What ancient country had no money?\n",
            "   a) Mozambique\n",
            "   b) Israel\n",
            "   c) Somali peninsula\n",
            "   d) Egypt\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "17) Government and religion were not separate in what ancient country?\n",
            "   a) Israel\n",
            "   b) Mauritania\n",
            "   c) Egypt\n",
            "   d) Nigeria\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "18) Who created a government that divided Egypt into 42 provinces?\n",
            "   a) Egyptians\n",
            "   b) Theban\n",
            "   c) Cairene\n",
            "   d) Copt\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "19) Who learned to be a scribe?\n",
            "   a) Theban\n",
            "   b) Nubian\n",
            "   c) Copt\n",
            "   d) Egyptians\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "20) What was the red color of the crown of Lower Egypt?\n",
            "   a) Crown\n",
            "   b) Hatband\n",
            "   c) Bark\n",
            "   d) A turnpike\n",
            "Answer is: crown\n",
            "\n",
            "\n",
            "21) In what country were the first rulers of Egypt buried?\n",
            "   a) Nigeria\n",
            "   b) Egypt\n",
            "   c) Somali peninsula\n",
            "   d) Sierra leone\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "22) What was the name of the upper Nile?\n",
            "   a) Nyala\n",
            "   b) Nile\n",
            "   c) Aswan\n",
            "   d) Kordofan\n",
            "Answer is: nile\n",
            "\n",
            "\n",
            "23) Where did people become slaves if they owed debt, committed crime, or were captured in war?\n",
            "   a) Jordan\n",
            "   b) Malawi\n",
            "   c) Egypt\n",
            "   d) Iran\n",
            "Answer is: egypt\n",
            "\n",
            "\n",
            "24) What river provided so much for Egyptians that they had surpluses?\n",
            "   a) Buganda\n",
            "   b) Kordofan\n",
            "   c) Nyala\n",
            "   d) Nile\n",
            "Answer is: nile\n",
            "\n",
            "\n",
            "25) Who was thought to be a god?\n",
            "   a) Cheops\n",
            "   b) Khufu\n",
            "   c) Pharaoh\n",
            "Answer is: pharaoh\n",
            "\n",
            "\n",
            "26) Who cut the stems into strips?\n",
            "   a) Nubian\n",
            "   b) Cairene\n",
            "   c) Theban\n",
            "   d) Egyptians\n",
            "Answer is: egyptians\n",
            "\n",
            "\n",
            "27) Where does the equator begin?\n",
            "   a) Old world\n",
            "   b) Eurasia\n",
            "   c) Australia\n",
            "   d) Africa\n",
            "Answer is: africa\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assesment of Questions and answers \n"
      ],
      "metadata": {
        "id": "aUOf5sVe3w8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def is_grammatical(sentence):\n",
        "    \"\"\"\n",
        "    Check if a sentence is grammatically correct\n",
        "    \"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    if any(token.tag_ == \"XX\" for token in doc):\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "def is_diverse(options):\n",
        "    \"\"\"\n",
        "    Check if a set of options is diverse\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    for option in options:\n",
        "        words.extend([word.lower() for word in nltk.word_tokenize(option)])\n",
        "    synsets = []\n",
        "    for word in words:\n",
        "        synsets.extend(wordnet.synsets(word))\n",
        "    unique_synsets = set(synsets)\n",
        "    if len(unique_synsets) > 1:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "score=0\n",
        "# Assess each MCQ and print the results\n",
        "for question in questions:\n",
        "    if is_grammatical(question[\"question\"]):\n",
        "        continue\n",
        "    else:\n",
        "        score+=1\n",
        "        print(\"Question:\", question[\"question\"])\n",
        "        print(\"The question is not grammatically correct.\")\n",
        "    if is_diverse(question[\"options\"]):\n",
        "        continue\n",
        "    else:\n",
        "        score+=1\n",
        "        print(\"Options:\", question[\"options\"])\n",
        "        print(\"The options are not diverse.\")\n",
        "\n",
        "if score==0:\n",
        "  print(\"Everything is good.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFXAlfly5u4v",
        "outputId": "aeeb1c0e-4320-407b-cacb-5ec989982c99"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything is good.\n"
          ]
        }
      ]
    }
  ]
}